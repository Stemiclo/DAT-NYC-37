{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 16: Mining data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unicode Handling\n",
    "from __future__ import unicode_literals\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the tweets we pulled from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run `capture-tweets.py` in the parent folder before running this cell.\n",
    "\n",
    "# Loading the tweet data\n",
    "filename = '../../assets/dataset/news-tweets.txt'\n",
    "\n",
    "tweets = []\n",
    "for tweet in codecs.open(filename, 'r', encoding=\"utf-8\"):\n",
    "    tweets.append(tweet)\n",
    "\n",
    "# Setting up spacy\n",
    "nlp_toolkit = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709647"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_word2vec = Word2Vec(size=300, min_count=10)\n",
    "tweets_word2vec.build_vocab(tweets)\n",
    "\n",
    "#Train the model over train_reviews (this may take several minutes)\n",
    "tweets_word2vec.train(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\n': <gensim.models.word2vec.Vocab at 0x111cdd290>,\n",
       " u'\\r': <gensim.models.word2vec.Vocab at 0x111cdd910>,\n",
       " u' ': <gensim.models.word2vec.Vocab at 0x111ccd5d0>,\n",
       " u'!': <gensim.models.word2vec.Vocab at 0x111cdd9d0>,\n",
       " u'\"': <gensim.models.word2vec.Vocab at 0x10aaa54d0>,\n",
       " u'#': <gensim.models.word2vec.Vocab at 0x111ccdc90>,\n",
       " u'$': <gensim.models.word2vec.Vocab at 0x111ccd650>,\n",
       " u'%': <gensim.models.word2vec.Vocab at 0x111cddd90>,\n",
       " u'&': <gensim.models.word2vec.Vocab at 0x111ccd990>,\n",
       " u\"'\": <gensim.models.word2vec.Vocab at 0x111ccdd50>,\n",
       " u'(': <gensim.models.word2vec.Vocab at 0x111ccd690>,\n",
       " u')': <gensim.models.word2vec.Vocab at 0x111cdda10>,\n",
       " u'*': <gensim.models.word2vec.Vocab at 0x111cdd2d0>,\n",
       " u'+': <gensim.models.word2vec.Vocab at 0x111ccdd90>,\n",
       " u',': <gensim.models.word2vec.Vocab at 0x111ccd6d0>,\n",
       " u'-': <gensim.models.word2vec.Vocab at 0x10bca69d0>,\n",
       " u'.': <gensim.models.word2vec.Vocab at 0x111cdd310>,\n",
       " u'/': <gensim.models.word2vec.Vocab at 0x111ccddd0>,\n",
       " u'0': <gensim.models.word2vec.Vocab at 0x111ccd710>,\n",
       " u'1': <gensim.models.word2vec.Vocab at 0x111cddad0>,\n",
       " u'2': <gensim.models.word2vec.Vocab at 0x111cdde10>,\n",
       " u'3': <gensim.models.word2vec.Vocab at 0x111ccde10>,\n",
       " u'4': <gensim.models.word2vec.Vocab at 0x111ccd750>,\n",
       " u'5': <gensim.models.word2vec.Vocab at 0x111cddb10>,\n",
       " u'6': <gensim.models.word2vec.Vocab at 0x111cdd350>,\n",
       " u'7': <gensim.models.word2vec.Vocab at 0x111ccde50>,\n",
       " u'8': <gensim.models.word2vec.Vocab at 0x111cdd5d0>,\n",
       " u'9': <gensim.models.word2vec.Vocab at 0x111cddb50>,\n",
       " u':': <gensim.models.word2vec.Vocab at 0x111cdd390>,\n",
       " u';': <gensim.models.word2vec.Vocab at 0x111ccde90>,\n",
       " u'=': <gensim.models.word2vec.Vocab at 0x111cddf10>,\n",
       " u'?': <gensim.models.word2vec.Vocab at 0x111ccded0>,\n",
       " u'@': <gensim.models.word2vec.Vocab at 0x111cdd8d0>,\n",
       " u'A': <gensim.models.word2vec.Vocab at 0x111cddbd0>,\n",
       " u'B': <gensim.models.word2vec.Vocab at 0x111cdd410>,\n",
       " u'C': <gensim.models.word2vec.Vocab at 0x111ccdf10>,\n",
       " u'D': <gensim.models.word2vec.Vocab at 0x111ccd810>,\n",
       " u'E': <gensim.models.word2vec.Vocab at 0x111cddc10>,\n",
       " u'F': <gensim.models.word2vec.Vocab at 0x111cdd450>,\n",
       " u'G': <gensim.models.word2vec.Vocab at 0x111ccdd10>,\n",
       " u'H': <gensim.models.word2vec.Vocab at 0x111ccd850>,\n",
       " u'I': <gensim.models.word2vec.Vocab at 0x111cddc50>,\n",
       " u'J': <gensim.models.word2vec.Vocab at 0x111cdd4d0>,\n",
       " u'K': <gensim.models.word2vec.Vocab at 0x111ccdf50>,\n",
       " u'L': <gensim.models.word2vec.Vocab at 0x111ccd890>,\n",
       " u'M': <gensim.models.word2vec.Vocab at 0x111cddc90>,\n",
       " u'N': <gensim.models.word2vec.Vocab at 0x111cdd510>,\n",
       " u'O': <gensim.models.word2vec.Vocab at 0x111ccdf90>,\n",
       " u'P': <gensim.models.word2vec.Vocab at 0x111ccd8d0>,\n",
       " u'Q': <gensim.models.word2vec.Vocab at 0x111cddcd0>,\n",
       " u'R': <gensim.models.word2vec.Vocab at 0x111cdd550>,\n",
       " u'S': <gensim.models.word2vec.Vocab at 0x111ccdfd0>,\n",
       " u'T': <gensim.models.word2vec.Vocab at 0x111ccd910>,\n",
       " u'U': <gensim.models.word2vec.Vocab at 0x111cddd10>,\n",
       " u'V': <gensim.models.word2vec.Vocab at 0x10bca6a10>,\n",
       " u'W': <gensim.models.word2vec.Vocab at 0x10aaa5450>,\n",
       " u'X': <gensim.models.word2vec.Vocab at 0x111ccd950>,\n",
       " u'Y': <gensim.models.word2vec.Vocab at 0x111cddd50>,\n",
       " u'Z': <gensim.models.word2vec.Vocab at 0x111cdd610>,\n",
       " u'[': <gensim.models.word2vec.Vocab at 0x109200dd0>,\n",
       " u']': <gensim.models.word2vec.Vocab at 0x111cdddd0>,\n",
       " u'^': <gensim.models.word2vec.Vocab at 0x111cdd650>,\n",
       " u'_': <gensim.models.word2vec.Vocab at 0x109200d90>,\n",
       " u'a': <gensim.models.word2vec.Vocab at 0x111cdd3d0>,\n",
       " u'b': <gensim.models.word2vec.Vocab at 0x111cdd6d0>,\n",
       " u'c': <gensim.models.word2vec.Vocab at 0x111cdd050>,\n",
       " u'd': <gensim.models.word2vec.Vocab at 0x111ccd9d0>,\n",
       " u'e': <gensim.models.word2vec.Vocab at 0x111cdde90>,\n",
       " u'f': <gensim.models.word2vec.Vocab at 0x111cdd710>,\n",
       " u'g': <gensim.models.word2vec.Vocab at 0x111cdd090>,\n",
       " u'h': <gensim.models.word2vec.Vocab at 0x111ccda10>,\n",
       " u'i': <gensim.models.word2vec.Vocab at 0x111cdded0>,\n",
       " u'j': <gensim.models.word2vec.Vocab at 0x111cdd750>,\n",
       " u'k': <gensim.models.word2vec.Vocab at 0x111cdd0d0>,\n",
       " u'l': <gensim.models.word2vec.Vocab at 0x111ccda90>,\n",
       " u'm': <gensim.models.word2vec.Vocab at 0x111cddf50>,\n",
       " u'n': <gensim.models.word2vec.Vocab at 0x111cdd790>,\n",
       " u'o': <gensim.models.word2vec.Vocab at 0x111cdd190>,\n",
       " u'p': <gensim.models.word2vec.Vocab at 0x111ccdad0>,\n",
       " u'q': <gensim.models.word2vec.Vocab at 0x111cddf90>,\n",
       " u'r': <gensim.models.word2vec.Vocab at 0x111cdd7d0>,\n",
       " u's': <gensim.models.word2vec.Vocab at 0x111cdd1d0>,\n",
       " u't': <gensim.models.word2vec.Vocab at 0x111ccdb10>,\n",
       " u'u': <gensim.models.word2vec.Vocab at 0x111cddfd0>,\n",
       " u'v': <gensim.models.word2vec.Vocab at 0x111cdd810>,\n",
       " u'w': <gensim.models.word2vec.Vocab at 0x111cdd210>,\n",
       " u'x': <gensim.models.word2vec.Vocab at 0x111ccdb50>,\n",
       " u'y': <gensim.models.word2vec.Vocab at 0x111ce0050>,\n",
       " u'z': <gensim.models.word2vec.Vocab at 0x111cdd850>,\n",
       " u'|': <gensim.models.word2vec.Vocab at 0x111ccdb90>,\n",
       " u'~': <gensim.models.word2vec.Vocab at 0x111cdd890>,\n",
       " u'\\xa0': <gensim.models.word2vec.Vocab at 0x111ccdc50>,\n",
       " u'\\u2013': <gensim.models.word2vec.Vocab at 0x111ccdbd0>,\n",
       " u'\\u2018': <gensim.models.word2vec.Vocab at 0x111ccdc10>,\n",
       " u'\\u2019': <gensim.models.word2vec.Vocab at 0x111cdd950>,\n",
       " u'\\u201c': <gensim.models.word2vec.Vocab at 0x111ccd550>,\n",
       " u'\\u201d': <gensim.models.word2vec.Vocab at 0x111cdda50>,\n",
       " u'\\u2026': <gensim.models.word2vec.Vocab at 0x111cdd110>,\n",
       " u'\\u21ac': <gensim.models.word2vec.Vocab at 0x111cdda90>,\n",
       " u'\\u3044': <gensim.models.word2vec.Vocab at 0x111cdd990>,\n",
       " u'\\u30bb': <gensim.models.word2vec.Vocab at 0x111ccd790>,\n",
       " u'\\u30d5': <gensim.models.word2vec.Vocab at 0x111cdd590>,\n",
       " u'\\u30e1': <gensim.models.word2vec.Vocab at 0x111cdd690>,\n",
       " u'\\u30eb': <gensim.models.word2vec.Vocab at 0x111ccda50>,\n",
       " u'\\u30ec': <gensim.models.word2vec.Vocab at 0x111cdd150>,\n",
       " u'\\u4f1a': <gensim.models.word2vec.Vocab at 0x111ccdcd0>,\n",
       " u'\\u51fa': <gensim.models.word2vec.Vocab at 0x111cdde50>,\n",
       " u'\\u53cb': <gensim.models.word2vec.Vocab at 0x111cdd490>,\n",
       " u'\\u5a5a': <gensim.models.word2vec.Vocab at 0x111ccd610>,\n",
       " u'\\ud83c': <gensim.models.word2vec.Vocab at 0x111ccd7d0>,\n",
       " u'\\ud83d': <gensim.models.word2vec.Vocab at 0x111cddb90>,\n",
       " u'\\ude02': <gensim.models.word2vec.Vocab at 0x111cdd250>,\n",
       " u'\\uff1a': <gensim.models.word2vec.Vocab at 0x10e527f90>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_word2vec.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u\"word 'Morning' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ae8f0da8f735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Morning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Aerlinger/.pyenv/versions/2.7.11/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u\"word 'Morning' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model = Word2Vec(\"\".join(tweets), size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "model.most_similar(\"Morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\n': <gensim.models.word2vec.Vocab at 0x118584790>,\n",
       " u'\\r': <gensim.models.word2vec.Vocab at 0x1185a62d0>,\n",
       " u' ': <gensim.models.word2vec.Vocab at 0x11859f0d0>,\n",
       " u'!': <gensim.models.word2vec.Vocab at 0x1185a6490>,\n",
       " u'\"': <gensim.models.word2vec.Vocab at 0x11266c6d0>,\n",
       " u'#': <gensim.models.word2vec.Vocab at 0x112664650>,\n",
       " u'$': <gensim.models.word2vec.Vocab at 0x11859fd50>,\n",
       " u'%': <gensim.models.word2vec.Vocab at 0x1185a6910>,\n",
       " u'&': <gensim.models.word2vec.Vocab at 0x112664e50>,\n",
       " u\"'\": <gensim.models.word2vec.Vocab at 0x11266cb10>,\n",
       " u'(': <gensim.models.word2vec.Vocab at 0x11859fd10>,\n",
       " u')': <gensim.models.word2vec.Vocab at 0x1185a64d0>,\n",
       " u'*': <gensim.models.word2vec.Vocab at 0x118584990>,\n",
       " u'+': <gensim.models.word2vec.Vocab at 0x11266cad0>,\n",
       " u',': <gensim.models.word2vec.Vocab at 0x11859fcd0>,\n",
       " u'-': <gensim.models.word2vec.Vocab at 0x11859f090>,\n",
       " u'.': <gensim.models.word2vec.Vocab at 0x1185849d0>,\n",
       " u'/': <gensim.models.word2vec.Vocab at 0x11266cb90>,\n",
       " u'0': <gensim.models.word2vec.Vocab at 0x11859fc50>,\n",
       " u'1': <gensim.models.word2vec.Vocab at 0x1185a65d0>,\n",
       " u'2': <gensim.models.word2vec.Vocab at 0x1185a6990>,\n",
       " u'3': <gensim.models.word2vec.Vocab at 0x11266c9d0>,\n",
       " u'4': <gensim.models.word2vec.Vocab at 0x112664510>,\n",
       " u'5': <gensim.models.word2vec.Vocab at 0x1185a6610>,\n",
       " u'6': <gensim.models.word2vec.Vocab at 0x118584a10>,\n",
       " u'7': <gensim.models.word2vec.Vocab at 0x11266ca50>,\n",
       " u'8': <gensim.models.word2vec.Vocab at 0x10bca6790>,\n",
       " u'9': <gensim.models.word2vec.Vocab at 0x1185a6650>,\n",
       " u':': <gensim.models.word2vec.Vocab at 0x1185846d0>,\n",
       " u';': <gensim.models.word2vec.Vocab at 0x11266ca10>,\n",
       " u'=': <gensim.models.word2vec.Vocab at 0x1185a6a90>,\n",
       " u'?': <gensim.models.word2vec.Vocab at 0x11266c850>,\n",
       " u'@': <gensim.models.word2vec.Vocab at 0x1185a6290>,\n",
       " u'A': <gensim.models.word2vec.Vocab at 0x1185a6710>,\n",
       " u'B': <gensim.models.word2vec.Vocab at 0x118584910>,\n",
       " u'C': <gensim.models.word2vec.Vocab at 0x11266c810>,\n",
       " u'D': <gensim.models.word2vec.Vocab at 0x112664a90>,\n",
       " u'E': <gensim.models.word2vec.Vocab at 0x1185a6750>,\n",
       " u'F': <gensim.models.word2vec.Vocab at 0x118584850>,\n",
       " u'G': <gensim.models.word2vec.Vocab at 0x11266cb50>,\n",
       " u'H': <gensim.models.word2vec.Vocab at 0x112664cd0>,\n",
       " u'I': <gensim.models.word2vec.Vocab at 0x1185a6790>,\n",
       " u'J': <gensim.models.word2vec.Vocab at 0x1185844d0>,\n",
       " u'K': <gensim.models.word2vec.Vocab at 0x11266c7d0>,\n",
       " u'L': <gensim.models.word2vec.Vocab at 0x112664d50>,\n",
       " u'M': <gensim.models.word2vec.Vocab at 0x1185a67d0>,\n",
       " u'N': <gensim.models.word2vec.Vocab at 0x10bca6dd0>,\n",
       " u'O': <gensim.models.word2vec.Vocab at 0x11266c790>,\n",
       " u'P': <gensim.models.word2vec.Vocab at 0x112664a10>,\n",
       " u'Q': <gensim.models.word2vec.Vocab at 0x1185a6850>,\n",
       " u'R': <gensim.models.word2vec.Vocab at 0x10bca6810>,\n",
       " u'S': <gensim.models.word2vec.Vocab at 0x11266c750>,\n",
       " u'T': <gensim.models.word2vec.Vocab at 0x112664fd0>,\n",
       " u'U': <gensim.models.word2vec.Vocab at 0x1185a6890>,\n",
       " u'V': <gensim.models.word2vec.Vocab at 0x11859f050>,\n",
       " u'W': <gensim.models.word2vec.Vocab at 0x11266c690>,\n",
       " u'X': <gensim.models.word2vec.Vocab at 0x112664f90>,\n",
       " u'Y': <gensim.models.word2vec.Vocab at 0x1185a68d0>,\n",
       " u'Z': <gensim.models.word2vec.Vocab at 0x10bca6ad0>,\n",
       " u'[': <gensim.models.word2vec.Vocab at 0x11266c650>,\n",
       " u']': <gensim.models.word2vec.Vocab at 0x1185a6950>,\n",
       " u'^': <gensim.models.word2vec.Vocab at 0x10bca6410>,\n",
       " u'_': <gensim.models.word2vec.Vocab at 0x11266cfd0>,\n",
       " u'a': <gensim.models.word2vec.Vocab at 0x1185847d0>,\n",
       " u'b': <gensim.models.word2vec.Vocab at 0x1185a6350>,\n",
       " u'c': <gensim.models.word2vec.Vocab at 0x11266c5d0>,\n",
       " u'd': <gensim.models.word2vec.Vocab at 0x112664e10>,\n",
       " u'e': <gensim.models.word2vec.Vocab at 0x1185a6a10>,\n",
       " u'f': <gensim.models.word2vec.Vocab at 0x1185a63d0>,\n",
       " u'g': <gensim.models.word2vec.Vocab at 0x11266c590>,\n",
       " u'h': <gensim.models.word2vec.Vocab at 0x112664dd0>,\n",
       " u'i': <gensim.models.word2vec.Vocab at 0x1185a6a50>,\n",
       " u'j': <gensim.models.word2vec.Vocab at 0x1185a6410>,\n",
       " u'k': <gensim.models.word2vec.Vocab at 0x11266c4d0>,\n",
       " u'l': <gensim.models.word2vec.Vocab at 0x112664b10>,\n",
       " u'm': <gensim.models.word2vec.Vocab at 0x1185a6ad0>,\n",
       " u'n': <gensim.models.word2vec.Vocab at 0x1185a6050>,\n",
       " u'o': <gensim.models.word2vec.Vocab at 0x118584d50>,\n",
       " u'p': <gensim.models.word2vec.Vocab at 0x112664990>,\n",
       " u'q': <gensim.models.word2vec.Vocab at 0x1185a6b10>,\n",
       " u'r': <gensim.models.word2vec.Vocab at 0x1185a6110>,\n",
       " u's': <gensim.models.word2vec.Vocab at 0x118584dd0>,\n",
       " u't': <gensim.models.word2vec.Vocab at 0x112664ad0>,\n",
       " u'u': <gensim.models.word2vec.Vocab at 0x1185a6b90>,\n",
       " u'v': <gensim.models.word2vec.Vocab at 0x1185a60d0>,\n",
       " u'w': <gensim.models.word2vec.Vocab at 0x118584650>,\n",
       " u'x': <gensim.models.word2vec.Vocab at 0x112664b90>,\n",
       " u'y': <gensim.models.word2vec.Vocab at 0x1185a6bd0>,\n",
       " u'z': <gensim.models.word2vec.Vocab at 0x1185a6190>,\n",
       " u'|': <gensim.models.word2vec.Vocab at 0x112664bd0>,\n",
       " u'~': <gensim.models.word2vec.Vocab at 0x1185a6210>,\n",
       " u'\\xa0': <gensim.models.word2vec.Vocab at 0x112664a50>,\n",
       " u'\\xed': <gensim.models.word2vec.Vocab at 0x1185a6150>,\n",
       " u'\\u0e04': <gensim.models.word2vec.Vocab at 0x11859f210>,\n",
       " u'\\u0e14': <gensim.models.word2vec.Vocab at 0x11859f590>,\n",
       " u'\\u0e22': <gensim.models.word2vec.Vocab at 0x118584e90>,\n",
       " u'\\u0e23': <gensim.models.word2vec.Vocab at 0x1185a6810>,\n",
       " u'\\u0e35': <gensim.models.word2vec.Vocab at 0x112664750>,\n",
       " u'\\u0e40': <gensim.models.word2vec.Vocab at 0x112664d90>,\n",
       " u'\\u2013': <gensim.models.word2vec.Vocab at 0x112664c90>,\n",
       " u'\\u2014': <gensim.models.word2vec.Vocab at 0x112664f50>,\n",
       " u'\\u2018': <gensim.models.word2vec.Vocab at 0x112664b50>,\n",
       " u'\\u2019': <gensim.models.word2vec.Vocab at 0x1185a6310>,\n",
       " u'\\u201c': <gensim.models.word2vec.Vocab at 0x11859f190>,\n",
       " u'\\u201d': <gensim.models.word2vec.Vocab at 0x1185a6510>,\n",
       " u'\\u2026': <gensim.models.word2vec.Vocab at 0x118584b90>,\n",
       " u'\\u20ac': <gensim.models.word2vec.Vocab at 0x11266cc10>,\n",
       " u'\\u21ac': <gensim.models.word2vec.Vocab at 0x1185a6590>,\n",
       " u'\\u2665': <gensim.models.word2vec.Vocab at 0x10bca6950>,\n",
       " u'\\u2714': <gensim.models.word2vec.Vocab at 0x1185845d0>,\n",
       " u'\\u2764': <gensim.models.word2vec.Vocab at 0x1185a6390>,\n",
       " u'\\u3044': <gensim.models.word2vec.Vocab at 0x1185a6450>,\n",
       " u'\\u30bb': <gensim.models.word2vec.Vocab at 0x1126649d0>,\n",
       " u'\\u30d5': <gensim.models.word2vec.Vocab at 0x10bca6710>,\n",
       " u'\\u30e1': <gensim.models.word2vec.Vocab at 0x10bca6990>,\n",
       " u'\\u30eb': <gensim.models.word2vec.Vocab at 0x112664ed0>,\n",
       " u'\\u30ec': <gensim.models.word2vec.Vocab at 0x118584950>,\n",
       " u'\\u4f1a': <gensim.models.word2vec.Vocab at 0x11266c350>,\n",
       " u'\\u51fa': <gensim.models.word2vec.Vocab at 0x1185a69d0>,\n",
       " u'\\u53cb': <gensim.models.word2vec.Vocab at 0x118584610>,\n",
       " u'\\u5a5a': <gensim.models.word2vec.Vocab at 0x11859f150>,\n",
       " u'\\u6599': <gensim.models.word2vec.Vocab at 0x11859fb10>,\n",
       " u'\\u6d3b': <gensim.models.word2vec.Vocab at 0x1185a6690>,\n",
       " u'\\u7121': <gensim.models.word2vec.Vocab at 0x112664950>,\n",
       " u'\\u7cfb': <gensim.models.word2vec.Vocab at 0x112664c50>,\n",
       " u'\\u7d50': <gensim.models.word2vec.Vocab at 0x10bca6610>,\n",
       " u'\\ud83c': <gensim.models.word2vec.Vocab at 0x1126648d0>,\n",
       " u'\\ud83d': <gensim.models.word2vec.Vocab at 0x1185a66d0>,\n",
       " u'\\ud83e': <gensim.models.word2vec.Vocab at 0x118584fd0>,\n",
       " u'\\udc47': <gensim.models.word2vec.Vocab at 0x112664f10>,\n",
       " u'\\udcb0': <gensim.models.word2vec.Vocab at 0x11266ca90>,\n",
       " u'\\ude01': <gensim.models.word2vec.Vocab at 0x1185a6250>,\n",
       " u'\\ude02': <gensim.models.word2vec.Vocab at 0x118584bd0>,\n",
       " u'\\ude0a': <gensim.models.word2vec.Vocab at 0x10bca6650>,\n",
       " u'\\ude0d': <gensim.models.word2vec.Vocab at 0x118584f50>,\n",
       " u'\\ude18': <gensim.models.word2vec.Vocab at 0x11859fb50>,\n",
       " u'\\ude29': <gensim.models.word2vec.Vocab at 0x1185a6b50>,\n",
       " u'\\udffb': <gensim.models.word2vec.Vocab at 0x1185a6090>,\n",
       " u'\\udffd': <gensim.models.word2vec.Vocab at 0x112664e90>,\n",
       " u'\\ufe0f': <gensim.models.word2vec.Vocab at 0x112664d10>,\n",
       " u'\\uff1a': <gensim.models.word2vec.Vocab at 0x11859f790>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1a\n",
    "\n",
    "Write a function that can take a take a sentence parsed by `spacy` and identify if it mentions a company named 'Google'. Remember, `spacy` can find entities and codes them as `ORG` if they are a company. Look at the slides for class 13 if you need a hint:\n",
    "\n",
    "### Bonus (1b)\n",
    "\n",
    "Parameterize the company name so that the function works for any company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_company(parsed):\n",
    "    # Return True if the sentence contains an organization and that organization is Google\n",
    "    for entity in parsed.ents:\n",
    "        # Fill in code here\n",
    "    # Otherwise return False\n",
    "    return False\n",
    "\n",
    "# 1b\n",
    "\n",
    "def mentions_company(parsed, company='Google'):\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c\n",
    "\n",
    "Write a function that can take a sentence parsed by `spacy` \n",
    "and return the verbs of the sentence (preferably lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_actions(parsed):\n",
    "    actions = []\n",
    "    # Your code here\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d\n",
    "For each tweet, parse it using spacy and print it out if the tweet has 'release' or 'announce' as a verb. You'll need to use your `mentions_company` and `get_actions` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1e\n",
    "Write a function that identifies countries - HINT: the entity label for countries is GPE (or GeoPolitical Entity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_country(parsed, country):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1f\n",
    "\n",
    "Re-run (d) to find country tweets that discuss 'Iran' announcing or releasing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Build a `word2vec` model of the tweets we have collected using `gensim`.\n",
    "\n",
    "### Exercise 2a:\n",
    "First take the collection of tweets and tokenize them using spacy.\n",
    "\n",
    "* Think about how this should be done. \n",
    "* Should you only use upper-case or lower-case? \n",
    "* Should you remove punctuations or symbols? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                for x in nlp_toolkit(t)] for t in tweets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "Build a `word2vec` model.\n",
    "Test the window size as well - this is how many surrounding words need to be used to model a word. What do you think is appropriate for Twitter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text_split, size=100, window=4, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2c:\n",
    "Test your word2vec model with a few similarity functions. \n",
    "* Find words similar to 'Syria'.\n",
    "* Find words similar to 'war'.\n",
    "* Find words similar to \"Iran\".\n",
    "* Find words similar to 'Verizon'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Syria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2d\n",
    "\n",
    "Adjust the choices / parameters in (b) and (c) as necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Filter tweets to those that mention 'Iran' or similar entities and 'war' or similar entities.\n",
    "* Do this using just spacy.\n",
    "* Do this using word2vec similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using spacy\n",
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using word2vec similarity scores\n",
    "for tweet in tweets[:200]:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
